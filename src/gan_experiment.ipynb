{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "model_name = 'GAN_GEN'\n",
    "model_train_epochs_step=100\n",
    "model_train_epochs_stop=1000\n",
    "\n",
    "try:\n",
    "    os.mkdir(model_name)\n",
    "except:\n",
    "    print(\"Error creating directory!\")\n",
    "\n",
    "trainData = pd.read_csv(\"train.csv\")\n",
    "# Do we need to shuffle our train set???\n",
    "trainData = trainData.sample(frac=1)\n",
    "trainX = trainData.drop(columns=[\"Class\"])\n",
    "trainY = trainData.Class\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "testX = testData.drop(columns=[\"Class\"])\n",
    "testY = testData.Class\n",
    "\n",
    "combined = pd.DataFrame({\"iterations\":[], \"auroc\":[], \"auprc\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    generator=Sequential()\n",
    "    generator.add(Dense(units=30,input_dim=100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=60))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=90))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(30, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    return generator\n",
    "\n",
    "def create_discriminator():\n",
    "    discriminator=Sequential()\n",
    "    discriminator.add(Dense(90,input_dim=30))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "    discriminator.add(Dense(60))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    discriminator.add(Dense(30))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    return discriminator\n",
    "\n",
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator()\n",
    "discriminator = create_discriminator()\n",
    "gan = create_gan(discriminator, generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1,10000):\n",
    "\n",
    "    noise= np.random.normal(0,1, [500, 100])\n",
    "    synthetic_fakes = generator.predict(noise)\n",
    "    \n",
    "    selection = np.random.randint(low=0,high=trainData.shape[0],size=500)\n",
    "    trainBatchX = trainX.values[selection]\n",
    "    trainBatchY = trainY.values[selection]\n",
    "\n",
    "    trainBatchX = np.concatenate([trainBatchX, synthetic_fakes])\n",
    "    trainBatchY = np.concatenate([trainBatchY, np.ones(500)])\n",
    "\n",
    "    discriminator.trainable=True\n",
    "    discriminator.train_on_batch(trainBatchX, trainBatchY)\n",
    "    discriminator.trainable=False\n",
    "\n",
    "    noise=np.random.normal(0,1, [500, 100])\n",
    "    y_gen = np.ones(500)\n",
    "    gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "    if e % 1000 == 0:\n",
    "        print (\"Epoch \"+str(e/1000))\n",
    "        \n",
    "        discriminator.save(\"./\"+model_name+\"/model_e\"+str(e/1000)+\".h5\")\n",
    "        \n",
    "        predictY = discriminator.predict(testX)\n",
    "        fpr, tpr, thresholds_roc = roc_curve(testY, predictY)\n",
    "        roc = pd.DataFrame({'fpr':fpr,'tpr':tpr,'threshold':thresholds_roc})\n",
    "        roc.to_csv(\"./\"+model_name+\"/model_e\"+str(e/1000)+\"_roc.csv\")\n",
    "        auc_roc_score=roc_auc_score(testY, predictY)\n",
    "\n",
    "        precision, recall, thresholds_prc = precision_recall_curve(testY, predictY)\n",
    "        prc = pd.DataFrame({'precision':precision,'recall':recall,'threshold':np.append(thresholds_prc, np.NaN)})\n",
    "        prc.to_csv(\"./\"+model_name+\"/model_e\"+str(e/1000)+\"_prc.csv\")\n",
    "        auc_prc_score= auc(recall, precision)\n",
    "\n",
    "        # Pass the row elements as key value pairs to append() function \n",
    "        combined = combined.append({\"iterations\":e/1000, \"auroc\":auc_roc_score, \"auprc\": auc_prc_score}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"./\"+model_name+\"/model_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
